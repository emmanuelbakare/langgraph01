{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05e7972-4ffd-46c8-9794-feca72f907e6",
   "metadata": {},
   "source": [
    "# Basic implementation of Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baef30e7-19f5-449c-aa8f-ef8759a9d486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75def3b-1d1a-40f6-8978-59eeac641d9d",
   "metadata": {},
   "source": [
    "### Function to Retrieve a bible text from api and combine it as one text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2250132b-3798-433a-bd57-992acf20d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "## get bible passage from https://bible-api and return a string version of the bible\n",
    "\n",
    "def bible_text(passage: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches a Bible passage from Bible-API and returns it in a formatted string:\n",
    "    Example: \"Luke 15:1-2 1. Text 2. Text\"\n",
    "    \"\"\"\n",
    "    url = f\"https://bible-api.com/{passage.replace(' ', '%20')}?translation=kjv\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Error fetching passage: {response.status_code}\"\n",
    "\n",
    "    data = response.json()\n",
    "    reference = data.get(\"reference\", \"\")\n",
    "    verses = data.get(\"verses\", [])\n",
    "    \n",
    "    merged_verses = \" \".join(\n",
    "        [f'{v[\"verse\"]}. {v[\"text\"].strip()}' for v in verses]\n",
    "    )\n",
    "    final_text = f\"{reference} {merged_verses}\"\n",
    "    cleaned_text =re.sub(r'\\s+', ' ', final_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590559d-800f-493c-a3ce-bf7abeabf6f5",
   "metadata": {},
   "source": [
    "### Retrieve the text using the bible_text function and store it as a list of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b839ad6-a18c-4337-b993-2b6dd8c8400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs =[\n",
    "Document(page_content=bible_text(\"Luke 15\"), metadata={\"source\":\"Luke 15\"}),\n",
    "Document(page_content=bible_text(\"Psalm 1\"), metadata={\"source\":\"Psalm 1\"}),\n",
    "Document(page_content=bible_text(\"Psalm 124\"), metadata={\"source\":\"Psalm 124\"}),\n",
    "Document(page_content=bible_text(\"Psalm 2\"), metadata={\"source\":\"Psalm 2\"}),\n",
    "\n",
    "] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df63cce-0331-4f95-b314-591fda50dbf5",
   "metadata": {},
   "source": [
    "### creat an embedding function, create an embedding database db, using the function and the document as parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e78c352-3863-4248-a312-c8bebef18a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2588eb-9f4d-4665-9d88-39ba69417d8b",
   "metadata": {},
   "source": [
    "### Create a retriever configuration using the embedded db, then retrieve a question to get a set of similar result\n",
    "- it is from this 3 results (k=3) that you will now query (invoke) the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61804f71-1ff7-4016-a3e4-b84fc098e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever =db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3})\n",
    "\n",
    "question= \"what happened when the boy spent all he had\"\n",
    "try:\n",
    "    result = retriever.invoke(question)\n",
    "    # print(result)  # uncomment this if you want to see the response- this is a list of document excerpts with similarity to the question answer\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab0a1a75-49c2-4cff-9222-4968f0dbfeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate a prompt template that will be used to finally query the  result (list of similar answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dfb38df-9e4c-4198-aa04-fa507d79aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")  # get the llm\n",
    "\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context: {context} \n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)  # create the promptTemplate\n",
    "\n",
    "# function to convert the generated docs into one big chunk of text\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#this creates the chain, retreives the context and question using the previous doc response and the previous answer\n",
    "# this chain will use llm to only retreive result from the previous docs (context) (which is now merged into a big chunk of text with format_docs)\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(result),\n",
    "        \"question\": lambda x: x\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92f41e83-fce7-4901-b9a0-71595e20f92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When the younger son spent all he had, a mighty famine arose in the land, and he began to be in want. He then joined himself to a citizen of that country, who sent him into his fields to feed swine. The son was so hungry that he longed to fill his belly with the husks that the swine ate, but no one gave him anything. This situation led him to realize his dire circumstances and decide to return to his father, acknowledging his mistakes and asking for forgiveness."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  List each parable and give each one a title\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the context provided from Luke 15, there are three parables presented. Here is a summary of each parable along with a suggested title:\n",
       "\n",
       "1. **Parable of the Lost Sheep**:  \n",
       "   Title: \"The Lost Sheep\"  \n",
       "   Summary: A shepherd leaves ninety-nine sheep in the wilderness to search for one lost sheep. Upon finding it, he rejoices and calls his friends and neighbors to celebrate. This parable emphasizes the joy in heaven over one sinner who repents.\n",
       "\n",
       "2. **Parable of the Lost Coin**:  \n",
       "   Title: \"The Lost Coin\"  \n",
       "   Summary: A woman searches diligently for one lost coin out of ten. When she finds it, she calls her friends and neighbors to rejoice with her. This parable illustrates the joy in the presence of the angels over a sinner who repents.\n",
       "\n",
       "3. **Parable of the Prodigal Son**:  \n",
       "   Title: \"The Prodigal Son\"  \n",
       "   Summary: A younger son demands his inheritance, leaves home, and wastes his wealth in a far country. Facing hardship, he returns home, repents, and is warmly welcomed by his father, who celebrates his return. The parable also describes the reaction of the elder son, who feels neglected. The theme centers on forgiveness, redemption, and the joy of a lost soul returning home."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  what will God do to those that plan against me\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to Psalms 124 from the given context, those who plan against you would be like the enemies of Israel who couldn't overcome them because the Lord was on their side. Psalms 124 describes how the Lord protected Israel from being overwhelmed and consumed by their adversaries. Therefore, the implication is that God will protect you and help you escape from the plans of those who rise against you, much like Israel escaped from their enemies with God's intervention."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  what will God do to those that rage against me\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The context provided from Psalms 124 speaks to God being on the side of those who trust in Him, suggesting that He protects them from their adversaries. Specifically, verses 2-8 express that if it had not been for the Lord's intervention, the enemies would have overwhelmed them. Therefore, the implication is that God will protect and deliver you from those who rage against you, much like He did for Israel by not allowing them to be overwhelmed by their enemies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  why will God laugh at them\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The context you provided does not explicitly mention God laughing at anyone. However, the concept of God laughing at the wicked or the ungodly is found in other parts of the Bible, such as Psalms 2:4 and Psalms 37:13. In these verses, the reason for God's laughter is generally because he is sovereign and knows that their plans or plots against the righteous or against His purposes will ultimately fail. Godâ€™s laughter is an expression of His supreme power and the futility of opposition against His will."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question:  end\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "#     final_answer=qa_chain.invoke(question)\n",
    "user_input=question\n",
    "from IPython.display import display, Markdown\n",
    "while True:\n",
    "    if user_input.lower() in [\"exit\",\"end\",\"break\"]:\n",
    "        break;\n",
    "    final_answer = qa_chain.invoke(user_input)\n",
    "    # print(final_answer)\n",
    "    print(display(Markdown(final_answer)))\n",
    "    user_input = input(\"Question: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a41a674e-55eb-4e5b-a43d-4e646cfd4316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what happened when the boy spent all he had'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d0d68-131e-4318-8910-4eb4e2907fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AIenv)",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
