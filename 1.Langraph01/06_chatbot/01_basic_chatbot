from typing import TypedDict, Annotated
from langgraph.graph import add_messages, StateGraph, END
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, AIMessage
from dotenv import load_dotenv


load_dotenv()
# llm = ChatGroq(model="llama3-8b-8192")   # 8b model  - faster model
llm = ChatGroq(model="llama3-70b-8192")  # 70b model  x8 better but slower

class BasicChatState(TypedDict):
    messages: Annotated[list, add_messages]

def chatbot(state:BasicChatState)->BasicChatState:
    return {
        "messages": [llm.invoke(state["messages"])]  #
    }

graph = StateGraph(BasicChatState)

graph.add_node("chatbot", chatbot)
graph.set_entry_point("chatbot")

graph.add_edge("chatbot", END)

app = graph.compile()

while True:
    user_input = input("User: ")

    if user_input in ["exit","end"]:
        break 

    result = app.invoke({
        "messages":[HumanMessage(content=user_input)]
    })
    # print(result)
    print("AI:",result["messages"][-1].content)

