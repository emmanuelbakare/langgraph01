{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e442ea-57b7-4ad3-80bb-c19d2d3655c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------GENERATION CHAIN ---------\n",
      "first=ChatPromptTemplate(input_variables=['feedback', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a viral Twitter content creator.\\nCreate a highly engaging, witty, funny, and potentially viral tweet.\\nKeep it under 280 characters.\\nMake it sharp, clever, and shareable.\\nIf feedback is provided, improve the tweet based on that feedback.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['feedback', 'topic'], input_types={}, partial_variables={}, template='Topic: {topic}\\nPrevious feedback (if any): {feedback}\\n\\nGenerate the improved tweet:'), additional_kwargs={})]) middle=[] last=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'text_inputs': True, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'text_outputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x00000264A59734D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000264A5AA2D20>, root_client=<openai.OpenAI object at 0x00000264A59F5700>, root_async_client=<openai.AsyncOpenAI object at 0x00000264A5A3ECC0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
      "\n",
      "\n",
      "\n",
      "=== GENERATION ROUND 2 ===\n",
      "content='\"Lagos hustle in a nutshell: ðŸš¦Stuck in traffic for one hour to buy \\'turn your life around in 30 minutes\\' motivational CDs for â‚¦500. If that\\'s not the hustle paradox, I don\\'t know what is! ðŸ˜‚ðŸš—ðŸ’¨ #LagosLife #HustleHarder\"' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 81, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_18e61aa3bc', 'id': 'chatcmpl-DDyFiuo1wvd2cKIbqdJ0yTM3ZwCiM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019ca0ad-6a30-7212-a3cc-2ffd3c6a334d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 81, 'output_tokens': 64, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "=================TEST GENERATION=====================\n",
      "{'tweet': AIMessage(content='\"Lagos hustle in a nutshell: ðŸš¦Stuck in traffic for one hour to buy \\'turn your life around in 30 minutes\\' motivational CDs for â‚¦500. If that\\'s not the hustle paradox, I don\\'t know what is! ðŸ˜‚ðŸš—ðŸ’¨ #LagosLife #HustleHarder\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 81, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_18e61aa3bc', 'id': 'chatcmpl-DDyFiuo1wvd2cKIbqdJ0yTM3ZwCiM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ca0ad-6a30-7212-a3cc-2ffd3c6a334d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 81, 'output_tokens': 64, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal, Annotated\n",
    "from operator import add\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ----------------------------\n",
    "# LLM Configuration\n",
    "# ----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Prompt Templates\n",
    "# ----------------------------\n",
    "\n",
    "generate_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a viral Twitter content creator.\n",
    "Create a highly engaging, witty, funny, and potentially viral tweet.\n",
    "Keep it under 280 characters.\n",
    "Make it sharp, clever, and shareable.\n",
    "If feedback is provided, improve the tweet based on that feedback.\"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"Topic: {topic}\n",
    "Previous feedback (if any): {feedback}\n",
    "\n",
    "Generate the improved tweet:\"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a viral Twitter growth expert and humor analyst.\n",
    "\n",
    "Evaluate the tweet based on:\n",
    "1. Humor\n",
    "2. Virality potential\n",
    "3. Engagement likelihood\n",
    "4. Clarity and punch\n",
    "\n",
    "Return your response strictly in JSON format:\n",
    "\n",
    "{{\n",
    "  \"score\": <integer 1-10>,\n",
    "  \"feedback\": \"<clear actionable improvement suggestions>\"\n",
    "}}\n",
    "\n",
    "Be critical. Only give 8 or above if it's genuinely strong.\"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"Tweet:\n",
    "{tweet}\"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generate_chain = generate_prompt | llm | StrOutputParser()\n",
    "reflection_chain = reflection_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"----------GENERATION CHAIN ---------\")\n",
    "print(generate_chain)\n",
    "print();print()\n",
    "\n",
    "# ----------------------------\n",
    "# State Definition\n",
    "# ----------------------------\n",
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    feedback: str\n",
    "    score: int\n",
    "    count: Annotated[int, add]  # reducer auto-adds\n",
    "    \n",
    "# ----------------------------\n",
    "# Nodes\n",
    "# ----------------------------\n",
    "\n",
    "def generate_tweet(state: TweetState):\n",
    "    tweet = generate_chain.invoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"feedback\": state.get(\"feedback\", \"\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== GENERATION ROUND {state.get('count', 0) + 1} ===\")\n",
    "    print(tweet)\n",
    "\n",
    "    return {\n",
    "        \"tweet\": tweet,\n",
    "        \"count\": 1  # reducer will increment\n",
    "    }\n",
    "\n",
    "response = generate_tweet({\n",
    "     \"topic\":\"Lagos Hustle\",\n",
    "     \"count\":1\n",
    "}) \n",
    "\n",
    "print();print()\n",
    "print(\"=================TEST GENERATION=====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccfc3a-e436-4351-911b-ba6f0cebe3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
