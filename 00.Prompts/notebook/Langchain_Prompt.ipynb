{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef9effc-d039-4ff6-b084-e1be19810242",
   "metadata": {},
   "source": [
    "# Langchain Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f3f8c-1d3a-4a75-9192-f26c874792a2",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Using PromptTemplate\n",
    "- This is the most common and flexible method. You define a prompt with placeholders that get filled in dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd422129-8189-4cd6-9104-ea884ca7285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "# llm = ChatGroq(model=\"llama3-8b-8192\")   # 8b model  - faster model\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\")  # 70b model  x8 better but slower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d232012-9ab8-4a44-b314-2507e73575f0",
   "metadata": {},
   "source": [
    "#### Use PrompTemplate.from_template to pass in a single simple prompt text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953d357-0eb8-4f9f-8ecb-481357a3d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Write a funny 3 line poem about {topic}\")\n",
    "formatted_prompt = prompt.format(topic=\"cats\")\n",
    "result = llm.invoke(formatted_prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9497c-1f6a-4beb-986a-8ba3616f1ef8",
   "metadata": {},
   "source": [
    "#### User PrompTemplate initialization with input_variables and template parametr and a LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2af2023d-3e71-4c20-9e72-49779a0a0001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are three benefits of using soap:\\n\\n1. **Cleansing**: Soap helps to remove dirt, oil, and other impurities from the skin, leaving it feeling clean and fresh. This is especially important for personal hygiene and preventing the spread of illnesses.\\n2. **Skin Health**: Soap can help to maintain healthy skin by removing bacteria and other microorganisms that can cause infections and skin conditions like acne. Many soaps also contain moisturizing ingredients that help to keep the skin hydrated and soft.\\n3. **Prevention of Infections**: Soap has been shown to be effective in preventing the spread of infections, including those caused by germs like influenza, norovirus, and MRSA. By washing your hands regularly with soap, you can reduce the risk of getting sick and prevent the spread of illnesses to others.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"product\"],\n",
    "    template = \"List 3 benefits of using {product}\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "result = chain.invoke({\"product\":\"soap\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7960f-3a66-4acd-b860-b58dabbee494",
   "metadata": {},
   "source": [
    "####  you can also do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec6956ce-18b2-440e-aa21-4d20d522ace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are 3 benefits of using soap:\\n\\n1. **Cleans and removes dirt and germs**: Soap helps to remove dirt, grime, and germs from the skin, which can help to prevent the spread of illnesses and infections. By washing with soap, you can remove bacteria, viruses, and other microorganisms that can cause harm.\\n2. **Moisturizes and softens skin**: Many soaps contain moisturizing ingredients that help to soften and hydrate the skin. This can be especially beneficial for people with dry or sensitive skin, as soap can help to lock in moisture and reduce irritation.\\n3. **Freshens and deodorizes**: Soap can leave your skin feeling fresh and clean, and can also help to eliminate body odor. Many soaps contain fragrances or antibacterial agents that can help to reduce sweat and odor, leaving you feeling confident and fresh throughout the day.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"product\"],\n",
    "    template = \"List 3 benefits of using {product}\"\n",
    ")\n",
    "final_prompt =prompt.format(product=\"soap\")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke(final_prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671056a-d65e-4e51-9c0c-f6d760a43b74",
   "metadata": {},
   "source": [
    "#### You can use Prompt_template.from_template to pass in a simple template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c96a0ea-c183-4af2-be8a-3a6c00123870",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 2. Using ChatPromptTemplate for Chat Models\n",
    "- Designed for chat-based models (like OpenAI's gpt-3.5/4). Supports message roles (user, system, assistant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e00214f-dc4e-4c3f-92f7-757f703efe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War Three's a blast,\n",
      "Nukes are flying fast,\n",
      "We're all toast at last!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# llm and output_parser defined in previous cells\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are an AI assistant that only output 3 line funny poem\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"write about {topic}\")\n",
    "])\n",
    "\n",
    "chain  = prompt | llm | output_parser\n",
    "\n",
    "result = chain.invoke({\"topic\":\"third world war\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429e03f-d6f8-492f-9cda-76b333451f1d",
   "metadata": {},
   "source": [
    "#### for ChatPromptTemplate you can also do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63646d69-2fd7-4693-b5b0-aa1ad5e5488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI's on the rise, they say,\n",
      "Taking over soon, in a major way,\n",
      "But first, it needs a coffee break!\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate takin a list of tuples options \"system\", \"human\",\"ai\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "   (\"system\",\"You are an AI assistant that only output 3 line funny poem\"),\n",
    "    (\"human\",\"write about {topic}\")\n",
    "])\n",
    "\n",
    "chain  = prompt | llm | output_parser\n",
    "\n",
    "formatted_prompt = prompt.format_messages(topic=\"artificial intelligence\") ## pass in a format  instead of chain invoke\n",
    "result = chain.invoke(formatted_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e43158-f81e-4ea5-b2e2-dbe78ee71b5c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 3. FewShotPromptTemplate\n",
    "- Creates prompts with multiple examples for few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7b64d8b-0702-4ac5-b359-0c077c3480c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"input\",\"output\"],\n",
    "    template= \"Input {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "shot_prompt = FewShotPromptTemplate(\n",
    "    examples= examples,\n",
    "    example_prompt=prompt,\n",
    "    prefix=\"Give the opposite of each word\",\n",
    "    suffix=\"Input {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")\n",
    "\n",
    "chain = shot_prompt | llm | output_parser\n",
    "result = chain.invoke({\"adjective\":\"boy\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "048c8f54-80e5-4857-b9c0-469b1d9bbb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is content='' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 28, 'total_tokens': 29, 'completion_time': 0.00796435, 'prompt_time': 0.000491702, 'queue_time': -9223372036.855268, 'total_time': 0.008456052}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None} id='run--1fa92f7c-7e4c-4334-b35e-0002c1986c07-0' usage_metadata={'input_tokens': 28, 'output_tokens': 1, 'total_tokens': 29}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# full_prompt = ChatPromptTemplate.from_messages(\n",
    "#     (\"syste,\",\"you are an Maths assistant\"),\n",
    "#     few_shot_prompt,\n",
    "#     (\"human\",\"{input}\")\n",
    "# )\n",
    "\n",
    "chain = few_shot_prompt | llm  #| output_parser\n",
    "result = chain.invoke({\"input\":\"5 + 7\"})\n",
    "print(\"Result is\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d0da9-26ea-4abd-8841-b2fd91339be8",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "4. ## Importing prompt from langchain hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9c45fd3-d7ee-409e-b7c9-4c13eb1fc117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\codes\\ai\\lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a quiz generator assistant, expert in crafting quizzes. Please ask me a quiz-related query.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    " \n",
    "\n",
    "# prompt = hub.pull(\"homanp/question-answer-pair\")\n",
    "prompt = hub.pull(\"poem/task_poem_generater\")\n",
    "\n",
    "chat = prompt |llm|output_parser\n",
    "# result = chat.invoke({\"number_of_pairs\": \"3\",\"data_format\":\"Y-m-d\",\"context\":\"question about school\"})\n",
    "result = chat.invoke({\"topic\":\"Write a poem about cats, in 8 lines\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4422dc-8cf6-42ef-b390-ee45698f0f1d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "##  5. Using PipelinePromptTemplate\n",
    "- Allows combining multiple prompt templates in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee54ea49-fd67-4433-8d14-ec6fdd5d302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary in 10 words: \"Demande de traduction et de résumé en 10 mots.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "question_one = PromptTemplate.from_template(\"Translate this text to French: {text}\")\n",
    "question_final = PromptTemplate.from_template(\"Summarize this in 10 words: {translated_text}\")\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=question_final,\n",
    "    pipeline_prompts = [\n",
    "         (\"translated_text\", question_one),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "final_prompt= pipeline_prompt.format(text=\"Hello, how are you?\")\n",
    "chain = prompt | llm | output_parser\n",
    "result = chain.invoke(final_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3b30e-77e4-41b7-80a3-aa6a60585036",
   "metadata": {},
   "source": [
    "#### Another Example of Multiple PipelinePromptTemplate\n",
    "- This code works with 3 templates uncommend the extra templates to add another level of promptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "332e0495-2b5c-4751-b44a-19f831dd1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the outline in 3 sentences:\n",
      "\n",
      "The question to be answered is \"What is the significance of artificial intelligence?\" To address this question, the outline explores the definition and history of artificial intelligence, its current applications and benefits, and its potential future implications on society and humanity. Through this examination, the outline aims to provide a comprehensive understanding of the significance of artificial intelligence in today's world.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "# Step 1: Turn topic into a question\n",
    "question_template = PromptTemplate.from_template(\"Turn the following topic into a question: {topic}\")\n",
    "# Step 2: Create an outline for that question\n",
    "outline_template = PromptTemplate.from_template(\"Create an outline to answer this question: {question}\")\n",
    "# Step 3: Summarize the outline\n",
    "summary_template = PromptTemplate.from_template(\"Summarize this outline in 3 sentences: {outline}\")\n",
    "emoji_template = PromptTemplate.from_template(\"add Emojis to this summary: {summary}\")\n",
    "\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=summary_template,\n",
    "    # final_prompt=emoji_template,\n",
    "    pipeline_prompts=[\n",
    "        (\"question\", question_template),   # question depends on 'topic'\n",
    "        (\"outline\", outline_template),     # outline depends on 'question'\n",
    "        # (\"summary\", summary_template)    # summary depends on 'outline'\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = pipeline_prompt | llm | output_parser\n",
    "result = chain.invoke({\"topic\":\"Artificial Intelligence\"})\n",
    "print(result)\n",
    "\n",
    "\n",
    "## see the prompts all together\n",
    "merged_prompt = pipeline_prompt.format(topic=\"Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7232cbb-79ca-4da1-9ebf-e55b01f3a918",
   "metadata": {},
   "source": [
    "#### if you combine the pipeline prompt using .format, it merges the question together\n",
    "- If you pass the merged text from pipeline_prompt.format into a PromptTemplate, the result will not be the same\n",
    "- in a way, PipelinePrompt act as if you actually did multiple calls to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42b1b4ba-cfe9-4de6-92d1-fbb8fa64f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize this outline in 3 sentences: Create an outline to answer this question: Turn the following topic into a question: Artificial Intelligence'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " merged_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fd66c82-8fe9-44eb-a2ca-6ece53fcad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the topic, and I'll convert it into a question, create an outline to answer it, and summarize the outline in 3 sentences.\n",
      "\n",
      "(Note: If you don't provide a topic, I'll assume you want to use \"Artificial Intelligence\" as the topic.)\n",
      "\n",
      "**Topic:** Artificial Intelligence\n",
      "\n",
      "**Question:** What are the current applications and potential future developments of Artificial Intelligence?\n",
      "\n",
      "**Outline:**\n",
      "\n",
      "I. Introduction\n",
      "\n",
      "* Brief overview of AI and its growing importance\n",
      "* Thesis statement: AI has numerous current applications and potential future developments that are transforming various industries.\n",
      "\n",
      "II. Current Applications of AI\n",
      "\n",
      "* Natural Language Processing (NLP) in virtual assistants and chatbots\n",
      "* Machine Learning in image and speech recognition\n",
      "* AI in healthcare for diagnosis and treatment\n",
      "* AI-powered robots in manufacturing and logistics\n",
      "* AI in finance for risk management and investment analysis\n",
      "\n",
      "III. Potential Future Developments of AI\n",
      "\n",
      "* Advancements in Deep Learning and Neural Networks\n",
      "* Increased use of AI in autonomous vehicles and drones\n",
      "* AI-powered cybersecurity systems for threat detection and prevention\n",
      "* AI-assisted education and personalized learning\n",
      "* Potential risks and challenges of AI development, such as job displacement and bias\n",
      "\n",
      "IV. Conclusion\n",
      "\n",
      "* Recap of current AI applications and potential future developments\n",
      "* Discussion of the need for responsible AI development and regulation\n",
      "* Final thoughts on the transformative power of AI\n",
      "\n",
      "**Summary in 3 sentences:**\n",
      "\n",
      "Artificial Intelligence has diverse current applications, including NLP, machine learning, and robotics, which are transforming industries such as healthcare, finance, and manufacturing. Future developments in AI may include advancements in deep learning, autonomous vehicles, and AI-powered cybersecurity systems, as well as potential risks and challenges. As AI continues to evolve, it is essential to ensure responsible development and regulation to harness its transformative power while mitigating its potential negative consequences.\n"
     ]
    }
   ],
   "source": [
    "prompt_text= \"Artificial Intelligence.Turn the following topic into a question.Create an outline to answer this question.Summarize this outline in 3 sentences\"\n",
    "prompter = PromptTemplate.from_template(prompt_text)\n",
    "chain = prompter | llm | output_parser\n",
    "result = chain.invoke({\"topic\":\"Artificial Intelligence\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2361095-f654-4b4e-87de-eed8dbf852bf",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 6. Using StringPromptTemplate (Custom)\n",
    "- You can subclass StringPromptTemplate to define a custom way to format prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b03bd230-1c15-4ac9-a8eb-f92b8745fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a 3 line poem on Langchain'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "class CustomPrompter(StringPromptTemplate):\n",
    "    def format(self, **kwargs):\n",
    "        return f\"Write a 3 line poem on {kwargs['input']}\"\n",
    "\n",
    "\n",
    "prompt = CustomPrompter(input_variables=[\"input\"])\n",
    "new_prompt=prompt.format(input=\"Langchain\")\n",
    "\n",
    "new_prompt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e14b59-d7fe-4ce5-81a8-5a3caf8cc286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada040d-0f2f-40b1-801a-b9cc35697fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AIenv)",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
